{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaming Events Social Scraper\n",
    "\n",
    "This notebook scrapes gaming events from social media sources (Facebook and Discord) and saves structured data to JSON files.\n",
    "\n",
    "## Features\n",
    "- Parse Facebook public posts and events for gaming events\n",
    "- Monitor Discord servers for event announcements\n",
    "- Extract structured data: game system, venue, date, time\n",
    "- Save events in consistent JSON schema\n",
    "- Extensible for additional platforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import requests\n",
    "from datetime import datetime, timezone\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import List, Optional, Dict, Any\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# For web scraping\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# For Discord (optional - requires bot setup)\n",
    "try:\n",
    "    import discord\n",
    "    DISCORD_AVAILABLE = True\n",
    "except ImportError:\n",
    "    DISCORD_AVAILABLE = False\n",
    "    print(\"Discord.py not available. Install with: pip install discord.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Event Data Schema\n",
    "\n",
    "Define the structure for gaming event data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class GamingEvent:\n",
    "    \"\"\"Structured data for a gaming event\"\"\"\n",
    "    title: str\n",
    "    game_system: str  # e.g., \"MTG\", \"Warhammer 40K\", \"D&D\"\n",
    "    venue: str        # Store/location name\n",
    "    date: str         # ISO format date\n",
    "    start_time: str   # Time in HH:MM format\n",
    "    source: str       # \"facebook\" or \"discord\"\n",
    "    source_url: Optional[str] = None\n",
    "    description: Optional[str] = None\n",
    "    extracted_at: str = None\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        if self.extracted_at is None:\n",
    "            self.extracted_at = datetime.now(timezone.utc).isoformat()\n",
    "    \n",
    "    def to_dict(self) -> Dict[str, Any]:\n",
    "        return asdict(self)\n",
    "\n",
    "class EventExtractor:\n",
    "    \"\"\"Base class for event extraction\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.game_keywords = [\n",
    "            \"mtg\", \"magic\", \"magic the gathering\",\n",
    "            \"warhammer\", \"40k\", \"age of sigmar\",\n",
    "            \"d&d\", \"dungeons and dragons\", \"dnd\",\n",
    "            \"pokemon\", \"yugioh\", \"digimon\",\n",
    "            \"fnm\", \"friday night magic\",\n",
    "            \"commander\", \"edh\",\n",
    "            \"draft\", \"sealed\", \"prerelease\"\n",
    "        ]\n",
    "        \n",
    "        self.time_patterns = [\n",
    "            r'(\\d{1,2}):?(\\d{2})\\s*(am|pm)',\n",
    "            r'(\\d{1,2})\\s*(am|pm)',\n",
    "            r'(\\d{1,2}):?(\\d{2})'\n",
    "        ]\n",
    "        \n",
    "        self.date_patterns = [\n",
    "            r'(\\d{1,2})/(\\d{1,2})/(\\d{4})',\n",
    "            r'(\\d{1,2})-(\\d{1,2})-(\\d{4})',\n",
    "            r'(january|february|march|april|may|june|july|august|september|october|november|december)\\s+(\\d{1,2})',\n",
    "            r'(jan|feb|mar|apr|may|jun|jul|aug|sep|oct|nov|dec)\\s+(\\d{1,2})'\n",
    "        ]\n",
    "    \n",
    "    def extract_game_system(self, text: str) -> str:\n",
    "        \"\"\"Extract game system from text\"\"\"\n",
    "        text_lower = text.lower()\n",
    "        \n",
    "        if any(keyword in text_lower for keyword in [\"mtg\", \"magic\", \"fnm\", \"commander\", \"edh\", \"draft\", \"sealed\", \"prerelease\"]):\n",
    "            return \"MTG\"\n",
    "        elif any(keyword in text_lower for keyword in [\"warhammer\", \"40k\", \"age of sigmar\"]):\n",
    "            return \"Warhammer\"\n",
    "        elif any(keyword in text_lower for keyword in [\"d&d\", \"dungeons\", \"dnd\"]):\n",
    "            return \"D&D\"\n",
    "        elif \"pokemon\" in text_lower:\n",
    "            return \"Pokemon\"\n",
    "        elif \"yugioh\" in text_lower:\n",
    "            return \"Yu-Gi-Oh\"\n",
    "        \n",
    "        return \"Unknown\"\n",
    "    \n",
    "    def extract_time(self, text: str) -> Optional[str]:\n",
    "        \"\"\"Extract time from text\"\"\"\n",
    "        for pattern in self.time_patterns:\n",
    "            match = re.search(pattern, text, re.IGNORECASE)\n",
    "            if match:\n",
    "                groups = match.groups()\n",
    "                if len(groups) == 3:  # HH:MM AM/PM\n",
    "                    hour, minute, period = groups\n",
    "                    return f\"{hour}:{minute} {period.upper()}\"\n",
    "                elif len(groups) == 2 and groups[1] in ['am', 'pm']:  # HH AM/PM\n",
    "                    hour, period = groups\n",
    "                    return f\"{hour}:00 {period.upper()}\"\n",
    "                elif len(groups) == 2:  # HH:MM (24hr)\n",
    "                    hour, minute = groups\n",
    "                    return f\"{hour}:{minute}\"\n",
    "        return None\n",
    "    \n",
    "    def extract_date(self, text: str) -> Optional[str]:\n",
    "        \"\"\"Extract date from text and convert to ISO format\"\"\"\n",
    "        for pattern in self.date_patterns:\n",
    "            match = re.search(pattern, text, re.IGNORECASE)\n",
    "            if match:\n",
    "                groups = match.groups()\n",
    "                # Handle different date formats\n",
    "                if len(groups) == 3 and groups[2].isdigit():  # MM/DD/YYYY\n",
    "                    month, day, year = groups\n",
    "                    return f\"{year}-{month.zfill(2)}-{day.zfill(2)}\"\n",
    "                elif len(groups) == 2:  # Month DD\n",
    "                    month_name, day = groups\n",
    "                    month_map = {\n",
    "                        'january': '01', 'jan': '01',\n",
    "                        'february': '02', 'feb': '02',\n",
    "                        'march': '03', 'mar': '03',\n",
    "                        'april': '04', 'apr': '04',\n",
    "                        'may': '05',\n",
    "                        'june': '06', 'jun': '06',\n",
    "                        'july': '07', 'jul': '07',\n",
    "                        'august': '08', 'aug': '08',\n",
    "                        'september': '09', 'sep': '09',\n",
    "                        'october': '10', 'oct': '10',\n",
    "                        'november': '11', 'nov': '11',\n",
    "                        'december': '12', 'dec': '12'\n",
    "                    }\n",
    "                    month = month_map.get(month_name.lower())\n",
    "                    if month:\n",
    "                        current_year = datetime.now().year\n",
    "                        return f\"{current_year}-{month}-{day.zfill(2)}\"\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Facebook Events Scraper\n",
    "\n",
    "Extract gaming events from Facebook pages and posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FacebookEventScraper(EventExtractor):\n",
    "    \"\"\"Scrape gaming events from Facebook\"\"\"\n",
    "    \n",
    "    def __init__(self, access_token: Optional[str] = None):\n",
    "        super().__init__()\n",
    "        self.access_token = access_token\n",
    "        self.base_url = \"https://graph.facebook.com/v18.0\"\n",
    "        \n",
    "    def scrape_page_events(self, page_id: str) -> List[GamingEvent]:\n",
    "        \"\"\"Scrape events from a Facebook page\"\"\"\n",
    "        events = []\n",
    "        \n",
    "        if not self.access_token:\n",
    "            print(\"Warning: No Facebook access token provided. Using public scraping fallback.\")\n",
    "            return self._scrape_public_page(page_id)\n",
    "        \n",
    "        try:\n",
    "            # Get page events via Graph API\n",
    "            url = f\"{self.base_url}/{page_id}/events\"\n",
    "            params = {\n",
    "                'access_token': self.access_token,\n",
    "                'fields': 'name,description,start_time,place'\n",
    "            }\n",
    "            \n",
    "            response = requests.get(url, params=params)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            data = response.json()\n",
    "            \n",
    "            for event_data in data.get('data', []):\n",
    "                event = self._parse_facebook_event(event_data, 'facebook_api')\n",
    "                if event:\n",
    "                    events.append(event)\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"Error scraping Facebook page {page_id}: {e}\")\n",
    "            \n",
    "        return events\n",
    "    \n",
    "    def _scrape_public_page(self, page_id: str) -> List[GamingEvent]:\n",
    "        \"\"\"Fallback method to scrape public Facebook page\"\"\"\n",
    "        events = []\n",
    "        \n",
    "        try:\n",
    "            # Note: This is a simplified example - Facebook's public pages\n",
    "            # are heavily JavaScript-rendered and may require selenium\n",
    "            url = f\"https://www.facebook.com/{page_id}/events\"\n",
    "            headers = {\n",
    "                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'\n",
    "            }\n",
    "            \n",
    "            response = requests.get(url, headers=headers)\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            \n",
    "            # Look for event-like content in the page\n",
    "            # This is a simplified approach - real implementation would need\n",
    "            # more sophisticated parsing\n",
    "            text_content = soup.get_text()\n",
    "            \n",
    "            # Look for gaming-related events in the text\n",
    "            lines = text_content.split('\\n')\n",
    "            for line in lines:\n",
    "                if any(keyword in line.lower() for keyword in self.game_keywords):\n",
    "                    event = self._parse_text_event(line, f\"https://facebook.com/{page_id}\")\n",
    "                    if event:\n",
    "                        events.append(event)\n",
    "                        \n",
    "        except Exception as e:\n",
    "            print(f\"Error scraping public Facebook page {page_id}: {e}\")\n",
    "            \n",
    "        return events\n",
    "    \n",
    "    def _parse_facebook_event(self, event_data: Dict, source_url: str) -> Optional[GamingEvent]:\n",
    "        \"\"\"Parse Facebook event data into GamingEvent\"\"\"\n",
    "        try:\n",
    "            title = event_data.get('name', '')\n",
    "            description = event_data.get('description', '')\n",
    "            \n",
    "            # Check if this is a gaming event\n",
    "            combined_text = f\"{title} {description}\".lower()\n",
    "            if not any(keyword in combined_text for keyword in self.game_keywords):\n",
    "                return None\n",
    "            \n",
    "            game_system = self.extract_game_system(combined_text)\n",
    "            \n",
    "            # Extract venue\n",
    "            venue = \"Unknown\"\n",
    "            place = event_data.get('place', {})\n",
    "            if isinstance(place, dict):\n",
    "                venue = place.get('name', 'Unknown')\n",
    "            \n",
    "            # Parse date/time\n",
    "            start_time_str = event_data.get('start_time', '')\n",
    "            if start_time_str:\n",
    "                try:\n",
    "                    dt = datetime.fromisoformat(start_time_str.replace('Z', '+00:00'))\n",
    "                    date = dt.date().isoformat()\n",
    "                    start_time = dt.time().strftime('%H:%M')\n",
    "                except:\n",
    "                    date = self.extract_date(combined_text) or \"Unknown\"\n",
    "                    start_time = self.extract_time(combined_text) or \"Unknown\"\n",
    "            else:\n",
    "                date = self.extract_date(combined_text) or \"Unknown\"\n",
    "                start_time = self.extract_time(combined_text) or \"Unknown\"\n",
    "            \n",
    "            return GamingEvent(\n",
    "                title=title,\n",
    "                game_system=game_system,\n",
    "                venue=venue,\n",
    "                date=date,\n",
    "                start_time=start_time,\n",
    "                source=\"facebook\",\n",
    "                source_url=source_url,\n",
    "                description=description\n",
    "            )\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing Facebook event: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def _parse_text_event(self, text: str, source_url: str) -> Optional[GamingEvent]:\n",
    "        \"\"\"Parse event from text content\"\"\"\n",
    "        game_system = self.extract_game_system(text)\n",
    "        if game_system == \"Unknown\":\n",
    "            return None\n",
    "        \n",
    "        date = self.extract_date(text) or \"Unknown\"\n",
    "        start_time = self.extract_time(text) or \"Unknown\"\n",
    "        \n",
    "        return GamingEvent(\n",
    "            title=text.strip()[:100],  # Limit title length\n",
    "            game_system=game_system,\n",
    "            venue=\"Unknown\",\n",
    "            date=date,\n",
    "            start_time=start_time,\n",
    "            source=\"facebook\",\n",
    "            source_url=source_url,\n",
    "            description=text.strip()\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discord Events Scraper\n",
    "\n",
    "Extract gaming events from Discord server channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscordEventScraper(EventExtractor):\n",
    "    \"\"\"Scrape gaming events from Discord servers\"\"\"\n",
    "    \n",
    "    def __init__(self, bot_token: Optional[str] = None):\n",
    "        super().__init__()\n",
    "        self.bot_token = bot_token\n",
    "        self.events = []\n",
    "        \n",
    "    async def scrape_server_events(self, guild_id: int, channel_names: List[str] = None) -> List[GamingEvent]:\n",
    "        \"\"\"Scrape events from Discord server channels\"\"\"\n",
    "        if not DISCORD_AVAILABLE:\n",
    "            print(\"Discord.py not available. Cannot scrape Discord events.\")\n",
    "            return []\n",
    "        \n",
    "        if not self.bot_token:\n",
    "            print(\"No Discord bot token provided.\")\n",
    "            return []\n",
    "        \n",
    "        if channel_names is None:\n",
    "            channel_names = ['events', 'schedule', 'announcements', 'general']\n",
    "        \n",
    "        intents = discord.Intents.default()\n",
    "        intents.message_content = True\n",
    "        \n",
    "        client = discord.Client(intents=intents)\n",
    "        \n",
    "        @client.event\n",
    "        async def on_ready():\n",
    "            try:\n",
    "                guild = client.get_guild(guild_id)\n",
    "                if not guild:\n",
    "                    print(f\"Guild {guild_id} not found\")\n",
    "                    await client.close()\n",
    "                    return\n",
    "                \n",
    "                for channel in guild.channels:\n",
    "                    if (isinstance(channel, discord.TextChannel) and \n",
    "                        any(name.lower() in channel.name.lower() for name in channel_names)):\n",
    "                        \n",
    "                        print(f\"Scanning channel: {channel.name}\")\n",
    "                        \n",
    "                        async for message in channel.history(limit=100):\n",
    "                            event = self._parse_discord_message(message)\n",
    "                            if event:\n",
    "                                self.events.append(event)\n",
    "                \n",
    "                await client.close()\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error scraping Discord server: {e}\")\n",
    "                await client.close()\n",
    "        \n",
    "        await client.start(self.bot_token)\n",
    "        return self.events\n",
    "    \n",
    "    def _parse_discord_message(self, message) -> Optional[GamingEvent]:\n",
    "        \"\"\"Parse Discord message for gaming events\"\"\"\n",
    "        try:\n",
    "            content = message.content\n",
    "            \n",
    "            # Check if this contains gaming keywords\n",
    "            if not any(keyword in content.lower() for keyword in self.game_keywords):\n",
    "                return None\n",
    "            \n",
    "            game_system = self.extract_game_system(content)\n",
    "            date = self.extract_date(content) or \"Unknown\"\n",
    "            start_time = self.extract_time(content) or \"Unknown\"\n",
    "            \n",
    "            # Try to extract venue from message\n",
    "            venue = \"Unknown\"\n",
    "            if hasattr(message, 'guild') and message.guild:\n",
    "                venue = message.guild.name\n",
    "            \n",
    "            return GamingEvent(\n",
    "                title=content[:100] if len(content) > 100 else content,\n",
    "                game_system=game_system,\n",
    "                venue=venue,\n",
    "                date=date,\n",
    "                start_time=start_time,\n",
    "                source=\"discord\",\n",
    "                source_url=f\"https://discord.com/channels/{message.guild.id}/{message.channel.id}/{message.id}\" if hasattr(message, 'guild') else None,\n",
    "                description=content\n",
    "            )\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing Discord message: {e}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Event Storage and Management\n",
    "\n",
    "Save and manage extracted events in JSON format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EventStorage:\n",
    "    \"\"\"Manage storage of gaming events\"\"\"\n",
    "    \n",
    "    def __init__(self, storage_dir: str = \"events_data\"):\n",
    "        self.storage_dir = Path(storage_dir)\n",
    "        self.storage_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "    def save_events(self, events: List[GamingEvent], filename: Optional[str] = None) -> str:\n",
    "        \"\"\"Save events to JSON file\"\"\"\n",
    "        if not filename:\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            filename = f\"gaming_events_{timestamp}.json\"\n",
    "        \n",
    "        filepath = self.storage_dir / filename\n",
    "        \n",
    "        events_data = {\n",
    "            \"scraped_at\": datetime.now(timezone.utc).isoformat(),\n",
    "            \"total_events\": len(events),\n",
    "            \"events\": [event.to_dict() for event in events]\n",
    "        }\n",
    "        \n",
    "        with open(filepath, 'w', encoding='utf-8') as f:\n",
    "            json.dump(events_data, f, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        print(f\"Saved {len(events)} events to {filepath}\")\n",
    "        return str(filepath)\n",
    "    \n",
    "    def load_events(self, filename: str) -> List[GamingEvent]:\n",
    "        \"\"\"Load events from JSON file\"\"\"\n",
    "        filepath = self.storage_dir / filename\n",
    "        \n",
    "        if not filepath.exists():\n",
    "            print(f\"File {filepath} does not exist\")\n",
    "            return []\n",
    "        \n",
    "        with open(filepath, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        events = []\n",
    "        for event_data in data.get('events', []):\n",
    "            event = GamingEvent(**event_data)\n",
    "            events.append(event)\n",
    "        \n",
    "        return events\n",
    "    \n",
    "    def get_events_by_game(self, game_system: str) -> List[GamingEvent]:\n",
    "        \"\"\"Get all events for a specific game system\"\"\"\n",
    "        all_events = []\n",
    "        \n",
    "        for json_file in self.storage_dir.glob(\"*.json\"):\n",
    "            events = self.load_events(json_file.name)\n",
    "            game_events = [e for e in events if e.game_system.lower() == game_system.lower()]\n",
    "            all_events.extend(game_events)\n",
    "        \n",
    "        return all_events\n",
    "    \n",
    "    def get_upcoming_events(self, days_ahead: int = 30) -> List[GamingEvent]:\n",
    "        \"\"\"Get events happening in the next N days\"\"\"\n",
    "        all_events = []\n",
    "        \n",
    "        for json_file in self.storage_dir.glob(\"*.json\"):\n",
    "            events = self.load_events(json_file.name)\n",
    "            all_events.extend(events)\n",
    "        \n",
    "        # Filter by date\n",
    "        today = datetime.now().date()\n",
    "        cutoff_date = today + datetime.timedelta(days=days_ahead)\n",
    "        \n",
    "        upcoming = []\n",
    "        for event in all_events:\n",
    "            try:\n",
    "                event_date = datetime.fromisoformat(event.date).date()\n",
    "                if today <= event_date <= cutoff_date:\n",
    "                    upcoming.append(event)\n",
    "            except:\n",
    "                continue  # Skip events with invalid dates\n",
    "        \n",
    "        # Sort by date\n",
    "        upcoming.sort(key=lambda x: x.date)\n",
    "        return upcoming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Scraper Orchestrator\n",
    "\n",
    "Coordinate scraping from multiple sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GamingEventsScraper:\n",
    "    \"\"\"Main orchestrator for gaming events scraping\"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 facebook_token: Optional[str] = None,\n",
    "                 discord_token: Optional[str] = None,\n",
    "                 storage_dir: str = \"events_data\"):\n",
    "        \n",
    "        self.facebook_scraper = FacebookEventScraper(facebook_token)\n",
    "        self.discord_scraper = DiscordEventScraper(discord_token)\n",
    "        self.storage = EventStorage(storage_dir)\n",
    "        \n",
    "    def scrape_all_sources(self, \n",
    "                          facebook_pages: List[str] = None,\n",
    "                          discord_servers: List[Dict] = None) -> List[GamingEvent]:\n",
    "        \"\"\"Scrape events from all configured sources\"\"\"\n",
    "        \n",
    "        all_events = []\n",
    "        \n",
    "        # Scrape Facebook\n",
    "        if facebook_pages:\n",
    "            print(\"Scraping Facebook pages...\")\n",
    "            for page_id in facebook_pages:\n",
    "                try:\n",
    "                    events = self.facebook_scraper.scrape_page_events(page_id)\n",
    "                    all_events.extend(events)\n",
    "                    print(f\"Found {len(events)} events from Facebook page {page_id}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error scraping Facebook page {page_id}: {e}\")\n",
    "        \n",
    "        # Scrape Discord (requires async)\n",
    "        if discord_servers and DISCORD_AVAILABLE:\n",
    "            print(\"Scraping Discord servers...\")\n",
    "            import asyncio\n",
    "            \n",
    "            async def scrape_discord():\n",
    "                discord_events = []\n",
    "                for server_config in discord_servers:\n",
    "                    try:\n",
    "                        guild_id = server_config['guild_id']\n",
    "                        channels = server_config.get('channels', None)\n",
    "                        events = await self.discord_scraper.scrape_server_events(guild_id, channels)\n",
    "                        discord_events.extend(events)\n",
    "                        print(f\"Found {len(events)} events from Discord server {guild_id}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error scraping Discord server: {e}\")\n",
    "                return discord_events\n",
    "            \n",
    "            # Run async Discord scraping\n",
    "            try:\n",
    "                discord_events = asyncio.run(scrape_discord())\n",
    "                all_events.extend(discord_events)\n",
    "            except Exception as e:\n",
    "                print(f\"Error running Discord scraping: {e}\")\n",
    "        \n",
    "        return all_events\n",
    "    \n",
    "    def scrape_and_save(self, \n",
    "                       facebook_pages: List[str] = None,\n",
    "                       discord_servers: List[Dict] = None,\n",
    "                       filename: Optional[str] = None) -> str:\n",
    "        \"\"\"Scrape events and save to file\"\"\"\n",
    "        \n",
    "        events = self.scrape_all_sources(facebook_pages, discord_servers)\n",
    "        \n",
    "        if not events:\n",
    "            print(\"No events found\")\n",
    "            return \"\"\n",
    "        \n",
    "        # Remove duplicates based on title and date\n",
    "        unique_events = []\n",
    "        seen = set()\n",
    "        \n",
    "        for event in events:\n",
    "            key = (event.title.lower().strip(), event.date, event.start_time)\n",
    "            if key not in seen:\n",
    "                unique_events.append(event)\n",
    "                seen.add(key)\n",
    "        \n",
    "        print(f\"Found {len(events)} total events, {len(unique_events)} unique\")\n",
    "        \n",
    "        # Save to file\n",
    "        filepath = self.storage.save_events(unique_events, filename)\n",
    "        \n",
    "        # Print summary\n",
    "        self._print_summary(unique_events)\n",
    "        \n",
    "        return filepath\n",
    "    \n",
    "    def _print_summary(self, events: List[GamingEvent]):\n",
    "        \"\"\"Print summary of scraped events\"\"\"\n",
    "        if not events:\n",
    "            return\n",
    "        \n",
    "        print(\"\\n=== EVENTS SUMMARY ===\")\n",
    "        \n",
    "        # Group by game system\n",
    "        by_game = {}\n",
    "        for event in events:\n",
    "            game = event.game_system\n",
    "            if game not in by_game:\n",
    "                by_game[game] = []\n",
    "            by_game[game].append(event)\n",
    "        \n",
    "        for game, game_events in by_game.items():\n",
    "            print(f\"\\n{game}: {len(game_events)} events\")\n",
    "            for event in sorted(game_events, key=lambda x: x.date)[:3]:  # Show first 3\n",
    "                print(f\"  - {event.title} | {event.date} {event.start_time} | {event.venue}\")\n",
    "            if len(game_events) > 3:\n",
    "                print(f\"  ... and {len(game_events) - 3} more\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration and Usage Examples\n",
    "\n",
    "Configure your scraping targets and run the scraper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "# Add your API tokens here (optional - will use public scraping fallbacks)\n",
    "FACEBOOK_ACCESS_TOKEN = None  # Get from Facebook Developers\n",
    "DISCORD_BOT_TOKEN = None      # Get from Discord Developer Portal\n",
    "\n",
    "# Configure scraping targets\n",
    "FACEBOOK_PAGES = [\n",
    "    # Add Facebook page IDs or usernames\n",
    "    # Example: \"yourlocalcardshop\", \"magicthegathering\"\n",
    "]\n",
    "\n",
    "DISCORD_SERVERS = [\n",
    "    # Add Discord server configurations\n",
    "    # Example: {\"guild_id\": 123456789, \"channels\": [\"events\", \"announcements\"]}\n",
    "]\n",
    "\n",
    "# Initialize scraper\n",
    "scraper = GamingEventsScraper(\n",
    "    facebook_token=FACEBOOK_ACCESS_TOKEN,\n",
    "    discord_token=DISCORD_BOT_TOKEN,\n",
    "    storage_dir=\"gaming_events_data\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Scraper\n",
    "\n",
    "Execute the scraping process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the scraper\n",
    "print(\"Starting gaming events scraper...\")\n",
    "\n",
    "try:\n",
    "    # Scrape and save events\n",
    "    output_file = scraper.scrape_and_save(\n",
    "        facebook_pages=FACEBOOK_PAGES,\n",
    "        discord_servers=DISCORD_SERVERS\n",
    "    )\n",
    "    \n",
    "    if output_file:\n",
    "        print(f\"\\nEvents saved to: {output_file}\")\n",
    "    else:\n",
    "        print(\"\\nNo events were found or saved.\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error running scraper: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Analyze Saved Events\n",
    "\n",
    "Work with previously scraped events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and analyze events\n",
    "storage = EventStorage(\"gaming_events_data\")\n",
    "\n",
    "# Get upcoming events\n",
    "upcoming = storage.get_upcoming_events(days_ahead=14)\n",
    "print(f\"\\nUpcoming events in next 14 days: {len(upcoming)}\")\n",
    "\n",
    "for event in upcoming[:5]:  # Show first 5\n",
    "    print(f\"- {event.title}\")\n",
    "    print(f\"  {event.game_system} | {event.date} {event.start_time} | {event.venue}\")\n",
    "    print(f\"  Source: {event.source}\")\n",
    "    print()\n",
    "\n",
    "# Get events by game\n",
    "mtg_events = storage.get_events_by_game(\"MTG\")\n",
    "print(f\"MTG events found: {len(mtg_events)}\")\n",
    "\n",
    "warhammer_events = storage.get_events_by_game(\"Warhammer\")\n",
    "print(f\"Warhammer events found: {len(warhammer_events)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing with Sample Data\n",
    "\n",
    "Test the extraction logic with sample text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test extraction with sample data\n",
    "extractor = EventExtractor()\n",
    "\n",
    "sample_texts = [\n",
    "    \"Friday Night Magic - Modern format at Card Kingdom, July 18th 7:00 PM\",\n",
    "    \"Warhammer 40K tournament this Saturday 10 AM at Games Workshop\",\n",
    "    \"D&D Adventurers League - Wed Aug 15 6:30pm at Local Game Store\",\n",
    "    \"Pokemon League Challenge on 8/20/2024 starting at 12:00 PM\"\n",
    "]\n",
    "\n",
    "print(\"Testing extraction logic:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for i, text in enumerate(sample_texts, 1):\n",
    "    print(f\"\\nSample {i}: {text}\")\n",
    "    print(f\"Game System: {extractor.extract_game_system(text)}\")\n",
    "    print(f\"Date: {extractor.extract_date(text)}\")\n",
    "    print(f\"Time: {extractor.extract_time(text)}\")\n",
    "    \n",
    "    # Create a sample event\n",
    "    event = GamingEvent(\n",
    "        title=text,\n",
    "        game_system=extractor.extract_game_system(text),\n",
    "        venue=\"Test Venue\",\n",
    "        date=extractor.extract_date(text) or \"Unknown\",\n",
    "        start_time=extractor.extract_time(text) or \"Unknown\",\n",
    "        source=\"test\"\n",
    "    )\n",
    "    \n",
    "    print(f\"Event JSON: {json.dumps(event.to_dict(), indent=2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "To expand this scraper:\n",
    "\n",
    "1. **Get API Credentials**:\n",
    "   - Facebook: Create a Facebook App and get an access token\n",
    "   - Discord: Create a Discord Bot and get a bot token\n",
    "\n",
    "2. **Add More Sources**:\n",
    "   - Reddit gaming communities\n",
    "   - Twitter/X gaming accounts\n",
    "   - Eventbrite gaming events\n",
    "   - Local gaming store websites\n",
    "\n",
    "3. **Improve Extraction**:\n",
    "   - Train ML models for better text parsing\n",
    "   - Add more game systems and keywords\n",
    "   - Improve date/time parsing\n",
    "\n",
    "4. **Add Features**:\n",
    "   - Duplicate detection across sources\n",
    "   - Event notifications\n",
    "   - Calendar export\n",
    "   - Web dashboard\n",
    "\n",
    "5. **Storage Options**:\n",
    "   - Database storage (PostgreSQL, MongoDB)\n",
    "   - Cloud storage (AWS S3, Google Cloud)\n",
    "   - Real-time updates"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}